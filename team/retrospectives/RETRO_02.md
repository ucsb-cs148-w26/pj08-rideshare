# Date of Retrospective: 02/13/26

* Led by: Wyatt Hamabe
* Present: Ruben Alvarez-Gutierrez, Moiez Baqar, Anna Gornyitzki, Hien Huynh, Tanvi Ladha, Wyatt Hamabe, Kenisha Vaswani, Joel Sanchez
* Absent: NA

## Start 
* Post PRs while assigning yourself
* Communicating when two people are reviewing/done reviewing a PR
* Adding acceptance criteria for user stories/subtasks on kanban board
* Check off these acceptance criteria once you're done
* Organizing Kanban board a little better, currently cluttered
* Label what feature a PR is fixing/changing

## Stop 
* Posting PRs without assigning yourself as a reviewer
* Leaving commented code in your PR

## Continue 
* This level of responsiveness and communication has been working well for attendance conflicts as well as project updates
* Adding screenshots
* 2 people reviewing per PR


## Action item 

* Goal: Code works as intended
* Experiment: Adding acceptance criteria to user stories/subtasks on kanban board  
* Measurable action item: Makes PR reviewing easier

* Keep up this level of communication and responsiveness in the groupchat! 

## Retro Assessment 
This retro continued to use the start, stop, continue outline. It kept it simple, with very similar communication as the previous retro, so it went pretty smoothly. Every member stayed on task w/ sharing and listening and resulted in actionable items for the team to move forward with.

## Experiment/Change 
Adding acceptance criteria to user stories/subtasks on kanban, so that we can test edge cases and preemptively fight bugs

## Experiment Results - UPDATED 02/20/2026
By 02/20/2026, we successfully implemented acceptance criteria for our user stories and subtasks on the Kanban board. Over the past week, most new tickets included clearly defined acceptance criteria, and team members checked them off before moving tasks to “Done.” This made PR reviews noticeably smoother, as reviewers had a concrete checklist to validate functionality and edge cases. We also improved PR hygiene by consistently assigning ourselves, labeling what feature was being updated, and removing commented-out code before merging. While adding acceptance criteria required a bit more upfront planning, it reduced back-and-forth during reviews and helped ensure the code worked as intended. Combined with maintaining two reviewers per PR and strong groupchat responsiveness, this experiment made our workflow more structured, transparent, and reliable.

